{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date  Dividends Ticker\n",
      "0  2018-02-09 00:00:00-05:00     0.1575   AAPL\n",
      "1  2018-05-11 00:00:00-04:00     0.1825   AAPL\n",
      "2  2018-08-10 00:00:00-04:00     0.1825   AAPL\n",
      "3  2018-11-08 00:00:00-05:00     0.1825   AAPL\n",
      "4  2019-02-08 00:00:00-05:00     0.1825   AAPL\n",
      "5  2019-05-10 00:00:00-04:00     0.1925   AAPL\n",
      "6  2019-08-09 00:00:00-04:00     0.1925   AAPL\n",
      "7  2019-11-07 00:00:00-05:00     0.1925   AAPL\n",
      "8  2020-02-07 00:00:00-05:00     0.1925   AAPL\n",
      "9  2020-05-08 00:00:00-04:00     0.2050   AAPL\n",
      "10 2020-08-07 00:00:00-04:00     0.2050   AAPL\n",
      "11 2020-11-06 00:00:00-05:00     0.2050   AAPL\n",
      "12 2021-02-05 00:00:00-05:00     0.2050   AAPL\n",
      "13 2021-05-07 00:00:00-04:00     0.2200   AAPL\n",
      "14 2021-08-06 00:00:00-04:00     0.2200   AAPL\n",
      "15 2021-11-05 00:00:00-04:00     0.2200   AAPL\n",
      "16 2022-02-04 00:00:00-05:00     0.2200   AAPL\n",
      "17 2022-05-06 00:00:00-04:00     0.2300   AAPL\n",
      "18 2022-08-05 00:00:00-04:00     0.2300   AAPL\n",
      "19 2022-11-04 00:00:00-04:00     0.2300   AAPL\n",
      "20 2018-02-14 00:00:00-05:00     0.4200   MSFT\n",
      "21 2018-05-16 00:00:00-04:00     0.4200   MSFT\n",
      "22 2018-08-15 00:00:00-04:00     0.4200   MSFT\n",
      "23 2018-11-14 00:00:00-05:00     0.4600   MSFT\n",
      "24 2019-02-20 00:00:00-05:00     0.4600   MSFT\n",
      "25 2019-05-15 00:00:00-04:00     0.4600   MSFT\n",
      "26 2019-08-14 00:00:00-04:00     0.4600   MSFT\n",
      "27 2019-11-20 00:00:00-05:00     0.5100   MSFT\n",
      "28 2020-02-19 00:00:00-05:00     0.5100   MSFT\n",
      "29 2020-05-20 00:00:00-04:00     0.5100   MSFT\n",
      "30 2020-08-19 00:00:00-04:00     0.5100   MSFT\n",
      "31 2020-11-18 00:00:00-05:00     0.5600   MSFT\n",
      "32 2021-02-17 00:00:00-05:00     0.5600   MSFT\n",
      "33 2021-05-19 00:00:00-04:00     0.5600   MSFT\n",
      "34 2021-08-18 00:00:00-04:00     0.5600   MSFT\n",
      "35 2021-11-17 00:00:00-05:00     0.6200   MSFT\n",
      "36 2022-02-16 00:00:00-05:00     0.6200   MSFT\n",
      "37 2022-05-18 00:00:00-04:00     0.6200   MSFT\n",
      "38 2022-08-17 00:00:00-04:00     0.6200   MSFT\n",
      "39 2022-11-16 00:00:00-05:00     0.6800   MSFT\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de tickers das ações que você quer analisar\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]  # Substitua com os tickers desejados\n",
    "\n",
    "# Data de início e fim para os dados de dividendos\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "\n",
    "# DataFrame para armazenar dados de dividendos\n",
    "dividend_data = pd.DataFrame()\n",
    "\n",
    "# Itera sobre os tickers e busca os dividendos\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    dividends = stock.dividends.loc[start_date:end_date]  # Obter dividendos no intervalo desejado\n",
    "    \n",
    "    # Adicionar uma coluna com o ticker para referência\n",
    "    dividends = dividends.reset_index()\n",
    "    dividends['Ticker'] = ticker\n",
    "    \n",
    "    # Armazena no DataFrame principal\n",
    "    dividend_data = pd.concat([dividend_data, dividends], ignore_index=True)\n",
    "\n",
    "# Exibir os dados de dividendos coletados\n",
    "print(dividend_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABC: possibly delisted; no timezone found\n",
      "$ADS: possibly delisted; no timezone found\n",
      "$AGN: possibly delisted; no timezone found\n",
      "$ALXN: possibly delisted; no timezone found\n",
      "$ANTM: possibly delisted; no timezone found\n",
      "$APC: possibly delisted; no timezone found\n",
      "$ARNC: possibly delisted; no timezone found\n",
      "$ATVI: possibly delisted; no timezone found\n",
      "$BBT: possibly delisted; no timezone found\n",
      "$BF.B: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$BHGE: possibly delisted; no timezone found\n",
      "$BLL: possibly delisted; no timezone found\n",
      "$BRK.B: possibly delisted; no timezone found\n",
      "$CBG: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$CBS: possibly delisted; no timezone found\n",
      "$CELG: possibly delisted; no timezone found\n",
      "$CERN: possibly delisted; no timezone found\n",
      "$COG: possibly delisted; no timezone found\n",
      "$CTL: possibly delisted; no timezone found\n",
      "$CTXS: possibly delisted; no timezone found\n",
      "$CXO: possibly delisted; no timezone found\n",
      "$DISCA: possibly delisted; no timezone found\n",
      "$DISCK: possibly delisted; no timezone found\n",
      "$DISH: possibly delisted; no timezone found\n",
      "$DPS: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$DRE: possibly delisted; no timezone found\n",
      "$DWDP: possibly delisted; no timezone found\n",
      "$ETFC: possibly delisted; no timezone found\n",
      "$FBHS: possibly delisted; no timezone found\n",
      "$FB: possibly delisted; no timezone found\n",
      "$FLIR: possibly delisted; no timezone found\n",
      "$GGP: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$GPS: possibly delisted; no timezone found\n",
      "$HCN: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$HRS: possibly delisted; no timezone found\n",
      "$JEC: possibly delisted; no timezone found\n",
      "$KORS: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$KSU: possibly delisted; no timezone found\n",
      "$LLL: possibly delisted; no timezone found\n",
      "$LUK: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$MON: possibly delisted; no timezone found\n",
      "$MYL: possibly delisted; no timezone found\n",
      "$NBL: possibly delisted; no timezone found\n",
      "$NLSN: possibly delisted; no timezone found\n",
      "$PBCT: possibly delisted; no timezone found\n",
      "$PCLN: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$PKI: possibly delisted; no timezone found\n",
      "$PXD: possibly delisted; no timezone found\n",
      "$RE: possibly delisted; no timezone found\n",
      "$RHT: possibly delisted; no timezone found\n",
      "$RTN: possibly delisted; no timezone found\n",
      "$SYMC: possibly delisted; no timezone found\n",
      "$TIF: possibly delisted; no timezone found\n",
      "$TMK: possibly delisted; no timezone found\n",
      "$TSS: possibly delisted; no timezone found\n",
      "$UTX: possibly delisted; no timezone found\n",
      "$VAR: possibly delisted; no timezone found\n",
      "$VIAB: possibly delisted; no timezone found\n",
      "$WLTW: possibly delisted; no timezone found\n",
      "$WRK: possibly delisted; no timezone found\n",
      "$WYN: possibly delisted; no price data found  (1d 1925-11-29 -> 2024-11-04)\n",
      "$XEC: possibly delisted; no timezone found\n",
      "$XLNX: possibly delisted; no timezone found\n",
      "$XL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 5 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     dividend_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dividend_data, dividends], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Renomear colunas\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdividend_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDividends\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 3. Calcular a Média dos Dividendos dos Últimos 5 Anos\u001b[39;00m\n\u001b[1;32m     28\u001b[0m average_dividends \u001b[38;5;241m=\u001b[39m dividend_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDividends\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/pandas/core/generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/pandas/core/generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/pandas/core/internals/managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/pandas/core/internals/base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 5 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 1. Listar todos os tickers do dataset S&P 500\n",
    "tickers = pd.read_csv('all_stocks_5yr.csv')['Name'].unique()\n",
    "\n",
    "# 2. Carregar Dividendos para Cada Ação\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "dividend_data = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    dividends = stock.dividends.loc[start_date:end_date]\n",
    "    dividends = dividends.reset_index()\n",
    "    dividends['Ticker'] = ticker\n",
    "    dividend_data = pd.concat([dividend_data, dividends], ignore_index=True)\n",
    "\n",
    "# Renomear colunas\n",
    "dividend_data.columns = ['Date', 'Dividends', 'Ticker']\n",
    "\n",
    "# 3. Calcular a Média dos Dividendos dos Últimos 5 Anos\n",
    "average_dividends = dividend_data.groupby('Ticker')['Dividends'].mean().reset_index()\n",
    "average_dividends.columns = ['Ticker', 'AverageDividend']\n",
    "\n",
    "# 4. Criar a Coluna-Alvo `target`\n",
    "average_dividends['target'] = np.where(average_dividends['AverageDividend'] > 0.06, 1, 0)\n",
    "\n",
    "# 5. Preparar Dados para Treino e Teste\n",
    "X = average_dividends[['AverageDividend']].values\n",
    "y = average_dividends['target'].values\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 6. Construir e Treinar a Rede Neural\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=1, activation='relu'),\n",
    "    Dense(5, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 7. Avaliar a Precisão do Modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Previsões\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "print(\"Classes previstas:\", predicted_classes.flatten())\n",
    "print(\"Classes reais:\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de tickers do dataset\n",
    "tickers = pd.read_csv('/caminho/para/arquivo/all_stocks_5yr.csv')['Name'].unique()\n",
    "\n",
    "# Datas de início e fim\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "dividend_data = pd.DataFrame()\n",
    "\n",
    "# Tickers problemáticos\n",
    "failed_tickers = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        dividends = stock.dividends.loc[start_date:end_date]\n",
    "        \n",
    "        # Verificar se há dados de dividendos\n",
    "        if dividends.empty:\n",
    "            raise ValueError(f\"{ticker} não possui dados de dividendos.\")\n",
    "        \n",
    "        # Organizar dados e adicionar à tabela\n",
    "        dividends = dividends.reset_index()\n",
    "        dividends['Ticker'] = ticker\n",
    "        dividend_data = pd.concat([dividend_data, dividends], ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar dados para {ticker}: {e}\")\n",
    "        failed_tickers.append(ticker)\n",
    "\n",
    "# Remover tickers problemáticos\n",
    "print(f\"Tickers removidos (deslistados ou com dados ausentes): {failed_tickers}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManchineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
