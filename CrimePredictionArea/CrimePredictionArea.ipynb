{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando o dataset\n",
    "data = pd.read_csv('/home/guilherme/Documentos/Crime_Data_from_2020_to_Present.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criar as Colunas de Ano, Mês e Dia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DR_NO</th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190326475</td>\n",
       "      <td>03/01/2020 12:00:00 AM</td>\n",
       "      <td>03/01/2020 12:00:00 AM</td>\n",
       "      <td>2130</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>VEHICLE - STOLEN</td>\n",
       "      <td>...</td>\n",
       "      <td>998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900 S  LONGWOOD                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0375</td>\n",
       "      <td>-118.3506</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200106753</td>\n",
       "      <td>02/09/2020 12:00:00 AM</td>\n",
       "      <td>02/08/2020 12:00:00 AM</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>BURGLARY FROM VEHICLE</td>\n",
       "      <td>...</td>\n",
       "      <td>998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000 S  FLOWER                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0444</td>\n",
       "      <td>-118.2628</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200320258</td>\n",
       "      <td>11/11/2020 12:00:00 AM</td>\n",
       "      <td>11/04/2020 12:00:00 AM</td>\n",
       "      <td>1700</td>\n",
       "      <td>3</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>BIKE - STOLEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400 W  37TH                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0210</td>\n",
       "      <td>-118.3002</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200907217</td>\n",
       "      <td>05/10/2023 12:00:00 AM</td>\n",
       "      <td>03/10/2020 12:00:00 AM</td>\n",
       "      <td>2037</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>SHOPLIFTING-GRAND THEFT ($950.01 &amp; OVER)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14000    RIVERSIDE                    DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1576</td>\n",
       "      <td>-118.4387</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220614831</td>\n",
       "      <td>08/18/2022 12:00:00 AM</td>\n",
       "      <td>08/17/2020 12:00:00 AM</td>\n",
       "      <td>1200</td>\n",
       "      <td>6</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>666</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900    TRANSIENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0944</td>\n",
       "      <td>-118.3277</td>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986495</th>\n",
       "      <td>242011172</td>\n",
       "      <td>08/20/2024 12:00:00 AM</td>\n",
       "      <td>08/17/2024 12:00:00 AM</td>\n",
       "      <td>2300</td>\n",
       "      <td>20</td>\n",
       "      <td>Olympic</td>\n",
       "      <td>2033</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "      <td>THEFT-GRAND ($950.01 &amp; OVER)EXCPT,GUNS,FOWL,LI...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3700    WILSHIRE                     BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0617</td>\n",
       "      <td>-118.3066</td>\n",
       "      <td>2024</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986496</th>\n",
       "      <td>240710284</td>\n",
       "      <td>07/24/2024 12:00:00 AM</td>\n",
       "      <td>07/23/2024 12:00:00 AM</td>\n",
       "      <td>1400</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>VEHICLE - STOLEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000 W  23RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0362</td>\n",
       "      <td>-118.3284</td>\n",
       "      <td>2024</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986497</th>\n",
       "      <td>240104953</td>\n",
       "      <td>01/15/2024 12:00:00 AM</td>\n",
       "      <td>01/15/2024 12:00:00 AM</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>745</td>\n",
       "      <td>VANDALISM - MISDEAMEANOR ($399 OR UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300 W  SUNSET                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0685</td>\n",
       "      <td>-118.2460</td>\n",
       "      <td>2024</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986498</th>\n",
       "      <td>240309674</td>\n",
       "      <td>04/24/2024 12:00:00 AM</td>\n",
       "      <td>04/24/2024 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLOWER                       ST</td>\n",
       "      <td>JEFFERSON                    BL</td>\n",
       "      <td>34.0215</td>\n",
       "      <td>-118.2868</td>\n",
       "      <td>2024</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986499</th>\n",
       "      <td>240910892</td>\n",
       "      <td>08/13/2024 12:00:00 AM</td>\n",
       "      <td>08/12/2024 12:00:00 AM</td>\n",
       "      <td>2300</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>VEHICLE - STOLEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6900    VESPER                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1961</td>\n",
       "      <td>-118.4510</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986500 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DR_NO               Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0       190326475  03/01/2020 12:00:00 AM  03/01/2020 12:00:00 AM      2130   \n",
       "1       200106753  02/09/2020 12:00:00 AM  02/08/2020 12:00:00 AM      1800   \n",
       "2       200320258  11/11/2020 12:00:00 AM  11/04/2020 12:00:00 AM      1700   \n",
       "3       200907217  05/10/2023 12:00:00 AM  03/10/2020 12:00:00 AM      2037   \n",
       "4       220614831  08/18/2022 12:00:00 AM  08/17/2020 12:00:00 AM      1200   \n",
       "...           ...                     ...                     ...       ...   \n",
       "986495  242011172  08/20/2024 12:00:00 AM  08/17/2024 12:00:00 AM      2300   \n",
       "986496  240710284  07/24/2024 12:00:00 AM  07/23/2024 12:00:00 AM      1400   \n",
       "986497  240104953  01/15/2024 12:00:00 AM  01/15/2024 12:00:00 AM       100   \n",
       "986498  240309674  04/24/2024 12:00:00 AM  04/24/2024 12:00:00 AM      1500   \n",
       "986499  240910892  08/13/2024 12:00:00 AM  08/12/2024 12:00:00 AM      2300   \n",
       "\n",
       "        AREA  AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0          7   Wilshire          784         1     510   \n",
       "1          1    Central          182         1     330   \n",
       "2          3  Southwest          356         1     480   \n",
       "3          9   Van Nuys          964         1     343   \n",
       "4          6  Hollywood          666         2     354   \n",
       "...      ...        ...          ...       ...     ...   \n",
       "986495    20    Olympic         2033         1     341   \n",
       "986496     7   Wilshire          788         1     510   \n",
       "986497     1    Central          101         2     745   \n",
       "986498     3  Southwest          358         1     230   \n",
       "986499     9   Van Nuys          914         1     510   \n",
       "\n",
       "                                              Crm Cd Desc  ... Crm Cd 2  \\\n",
       "0                                        VEHICLE - STOLEN  ...    998.0   \n",
       "1                                   BURGLARY FROM VEHICLE  ...    998.0   \n",
       "2                                           BIKE - STOLEN  ...      NaN   \n",
       "3                SHOPLIFTING-GRAND THEFT ($950.01 & OVER)  ...      NaN   \n",
       "4                                       THEFT OF IDENTITY  ...      NaN   \n",
       "...                                                   ...  ...      ...   \n",
       "986495  THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LI...  ...      NaN   \n",
       "986496                                   VEHICLE - STOLEN  ...      NaN   \n",
       "986497           VANDALISM - MISDEAMEANOR ($399 OR UNDER)  ...      NaN   \n",
       "986498     ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT  ...      NaN   \n",
       "986499                                   VEHICLE - STOLEN  ...      NaN   \n",
       "\n",
       "        Crm Cd 3 Crm Cd 4                                  LOCATION  \\\n",
       "0            NaN      NaN   1900 S  LONGWOOD                     AV   \n",
       "1            NaN      NaN   1000 S  FLOWER                       ST   \n",
       "2            NaN      NaN   1400 W  37TH                         ST   \n",
       "3            NaN      NaN  14000    RIVERSIDE                    DR   \n",
       "4            NaN      NaN                         1900    TRANSIENT   \n",
       "...          ...      ...                                       ...   \n",
       "986495       NaN      NaN   3700    WILSHIRE                     BL   \n",
       "986496       NaN      NaN   4000 W  23RD                         ST   \n",
       "986497       NaN      NaN   1300 W  SUNSET                       BL   \n",
       "986498       NaN      NaN           FLOWER                       ST   \n",
       "986499       NaN      NaN   6900    VESPER                       AV   \n",
       "\n",
       "                           Cross Street      LAT       LON  year month day  \n",
       "0                                   NaN  34.0375 -118.3506  2020     1   3  \n",
       "1                                   NaN  34.0444 -118.2628  2020     8   2  \n",
       "2                                   NaN  34.0210 -118.3002  2020     4  11  \n",
       "3                                   NaN  34.1576 -118.4387  2020    10   3  \n",
       "4                                   NaN  34.0944 -118.3277  2020    17   8  \n",
       "...                                 ...      ...       ...   ...   ...  ..  \n",
       "986495                              NaN  34.0617 -118.3066  2024    17   8  \n",
       "986496                              NaN  34.0362 -118.3284  2024    23   7  \n",
       "986497                              NaN  34.0685 -118.2460  2024    15   1  \n",
       "986498  JEFFERSON                    BL  34.0215 -118.2868  2024    24   4  \n",
       "986499                              NaN  34.1961 -118.4510  2024    12   8  \n",
       "\n",
       "[986500 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'] = data['DATE OCC'].str.split(' ').str[0].str.split('/').str[2].astype(int)\n",
    "data['month'] = data['DATE OCC'].str.split(' ').str[0].str.split('/').str[1].astype(int)\n",
    "data['day'] = data['DATE OCC'].str.split(' ').str[0].str.split('/').str[0].astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  1,  3,  9,  6, 18, 13, 19,  2, 10,  8, 20,  4, 21, 11, 12, 14,\n",
       "       15,  5, 16, 17])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AREA'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agrupar os Dados para contar a ocorrência de crimes por área, mês e ano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process = data.groupby(['AREA', 'month', 'year'])['AREA'].count().reset_index(name='counts')\n",
    "data_process.sort_values(by=['AREA', 'year', 'month'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo 1: Mês e Ano Discretizados, como variáveis de entrada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Discretização de ano e mês\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process['month'] = data_process['month'].astype('category')\n",
    "data_process['year'] = data_process['year'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Criar variáveis dummy para 'month' e 'year'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = pd.get_dummies(data_process, columns=['month', 'year'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dividir os dados de treino e teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dummies.drop(['counts', 'AREA'], axis=1)\n",
    "y = data_dummies['counts']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o modelo, fazer previsão e avaliar o MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806us/step - loss: 43677.3086 - mean_absolute_error: 156.7681 - mse: 43677.3086 - val_loss: 4503.8638 - val_mean_absolute_error: 48.8257 - val_mse: 4503.8638\n",
      "Epoch 2/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 762us/step - loss: 3998.3435 - mean_absolute_error: 47.3868 - mse: 3998.3435 - val_loss: 4498.4712 - val_mean_absolute_error: 49.2444 - val_mse: 4498.4712\n",
      "Epoch 3/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - loss: 4273.5088 - mean_absolute_error: 49.3941 - mse: 4273.5088 - val_loss: 4510.5713 - val_mean_absolute_error: 46.7139 - val_mse: 4510.5713\n",
      "Epoch 4/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 4078.9163 - mean_absolute_error: 47.9332 - mse: 4078.9163 - val_loss: 4460.0137 - val_mean_absolute_error: 48.9882 - val_mse: 4460.0137\n",
      "Epoch 5/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - loss: 4105.2231 - mean_absolute_error: 47.8610 - mse: 4105.2231 - val_loss: 4424.2207 - val_mean_absolute_error: 47.4855 - val_mse: 4424.2207\n",
      "Epoch 6/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - loss: 4077.5164 - mean_absolute_error: 47.4120 - mse: 4077.5164 - val_loss: 4369.1934 - val_mean_absolute_error: 47.5715 - val_mse: 4369.1934\n",
      "Epoch 7/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - loss: 4010.1177 - mean_absolute_error: 47.2760 - mse: 4010.1177 - val_loss: 4424.3701 - val_mean_absolute_error: 47.3119 - val_mse: 4424.3701\n",
      "Epoch 8/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - loss: 4474.5981 - mean_absolute_error: 49.0544 - mse: 4474.5981 - val_loss: 4674.7627 - val_mean_absolute_error: 47.3108 - val_mse: 4674.7627\n",
      "Epoch 9/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 4112.3857 - mean_absolute_error: 48.4510 - mse: 4112.3857 - val_loss: 4465.9004 - val_mean_absolute_error: 48.9552 - val_mse: 4465.9004\n",
      "Epoch 10/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - loss: 4376.2412 - mean_absolute_error: 49.5148 - mse: 4376.2412 - val_loss: 4404.9111 - val_mean_absolute_error: 48.0604 - val_mse: 4404.9111\n",
      "Epoch 11/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - loss: 4037.0491 - mean_absolute_error: 48.2243 - mse: 4037.0491 - val_loss: 4672.9575 - val_mean_absolute_error: 51.0862 - val_mse: 4672.9575\n",
      "Epoch 12/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 4144.3931 - mean_absolute_error: 47.7720 - mse: 4144.3931 - val_loss: 4513.8921 - val_mean_absolute_error: 47.8343 - val_mse: 4513.8921\n",
      "Epoch 13/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 4141.7080 - mean_absolute_error: 48.4908 - mse: 4141.7080 - val_loss: 4353.6284 - val_mean_absolute_error: 46.7724 - val_mse: 4353.6284\n",
      "Epoch 14/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 4309.7495 - mean_absolute_error: 48.2299 - mse: 4309.7495 - val_loss: 4313.6860 - val_mean_absolute_error: 48.1586 - val_mse: 4313.6860\n",
      "Epoch 15/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 4179.4692 - mean_absolute_error: 49.4603 - mse: 4179.4692 - val_loss: 4393.1294 - val_mean_absolute_error: 47.6341 - val_mse: 4393.1294\n",
      "Epoch 16/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - loss: 3891.5149 - mean_absolute_error: 47.2312 - mse: 3891.5149 - val_loss: 4299.2852 - val_mean_absolute_error: 47.8537 - val_mse: 4299.2852\n",
      "Epoch 17/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - loss: 4292.1274 - mean_absolute_error: 49.1062 - mse: 4292.1274 - val_loss: 4294.3408 - val_mean_absolute_error: 47.2316 - val_mse: 4294.3408\n",
      "Epoch 18/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 3970.9521 - mean_absolute_error: 46.9581 - mse: 3970.9521 - val_loss: 4339.2656 - val_mean_absolute_error: 48.4105 - val_mse: 4339.2656\n",
      "Epoch 19/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 3992.0229 - mean_absolute_error: 48.3290 - mse: 3992.0229 - val_loss: 4343.7412 - val_mean_absolute_error: 48.3747 - val_mse: 4343.7412\n",
      "Epoch 20/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 4302.2935 - mean_absolute_error: 47.8899 - mse: 4302.2935 - val_loss: 4464.8633 - val_mean_absolute_error: 49.5016 - val_mse: 4464.8633\n",
      "Epoch 21/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - loss: 4148.3867 - mean_absolute_error: 48.4738 - mse: 4148.3867 - val_loss: 4361.2017 - val_mean_absolute_error: 47.0894 - val_mse: 4361.2017\n",
      "Epoch 22/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - loss: 4113.3467 - mean_absolute_error: 47.4582 - mse: 4113.3467 - val_loss: 4294.3130 - val_mean_absolute_error: 48.0026 - val_mse: 4294.3130\n",
      "Epoch 23/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - loss: 3909.8960 - mean_absolute_error: 47.5216 - mse: 3909.8960 - val_loss: 4649.0273 - val_mean_absolute_error: 47.4857 - val_mse: 4649.0273\n",
      "Epoch 24/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 3933.3342 - mean_absolute_error: 46.9780 - mse: 3933.3342 - val_loss: 4337.8584 - val_mean_absolute_error: 48.4826 - val_mse: 4337.8584\n",
      "Epoch 25/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - loss: 3847.5640 - mean_absolute_error: 47.1247 - mse: 3847.5640 - val_loss: 4515.2627 - val_mean_absolute_error: 50.1243 - val_mse: 4515.2627\n",
      "Epoch 26/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - loss: 3849.6028 - mean_absolute_error: 46.8732 - mse: 3849.6028 - val_loss: 4474.4009 - val_mean_absolute_error: 50.1136 - val_mse: 4474.4009\n",
      "Epoch 27/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - loss: 4118.8848 - mean_absolute_error: 48.4745 - mse: 4118.8848 - val_loss: 4327.0293 - val_mean_absolute_error: 47.6220 - val_mse: 4327.0293\n",
      "Epoch 28/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - loss: 4186.6987 - mean_absolute_error: 47.5783 - mse: 4186.6987 - val_loss: 4240.3506 - val_mean_absolute_error: 47.9125 - val_mse: 4240.3506\n",
      "Epoch 29/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 4071.0688 - mean_absolute_error: 47.5457 - mse: 4071.0688 - val_loss: 4356.2031 - val_mean_absolute_error: 48.6494 - val_mse: 4356.2031\n",
      "Epoch 30/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - loss: 4093.8096 - mean_absolute_error: 48.8566 - mse: 4093.8096 - val_loss: 4399.7397 - val_mean_absolute_error: 49.2314 - val_mse: 4399.7397\n",
      "Epoch 31/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 3986.3901 - mean_absolute_error: 47.6532 - mse: 3986.3901 - val_loss: 4359.4595 - val_mean_absolute_error: 47.5200 - val_mse: 4359.4595\n",
      "Epoch 32/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - loss: 3905.6748 - mean_absolute_error: 46.2134 - mse: 3905.6748 - val_loss: 4377.8472 - val_mean_absolute_error: 47.1234 - val_mse: 4377.8472\n",
      "Epoch 33/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - loss: 3812.8542 - mean_absolute_error: 46.0817 - mse: 3812.8542 - val_loss: 4238.7534 - val_mean_absolute_error: 46.9979 - val_mse: 4238.7534\n",
      "Epoch 34/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 4156.5635 - mean_absolute_error: 48.1865 - mse: 4156.5635 - val_loss: 4260.9771 - val_mean_absolute_error: 48.4626 - val_mse: 4260.9771\n",
      "Epoch 35/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 3942.9080 - mean_absolute_error: 47.9340 - mse: 3942.9080 - val_loss: 4274.4028 - val_mean_absolute_error: 47.1169 - val_mse: 4274.4028\n",
      "Epoch 36/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - loss: 4393.1733 - mean_absolute_error: 49.4300 - mse: 4393.1733 - val_loss: 4351.9829 - val_mean_absolute_error: 47.2866 - val_mse: 4351.9829\n",
      "Epoch 37/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - loss: 3863.9841 - mean_absolute_error: 47.1287 - mse: 3863.9841 - val_loss: 4336.1211 - val_mean_absolute_error: 47.2131 - val_mse: 4336.1211\n",
      "Epoch 38/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 4100.7251 - mean_absolute_error: 48.2180 - mse: 4100.7251 - val_loss: 4346.2754 - val_mean_absolute_error: 47.3447 - val_mse: 4346.2754\n",
      "Epoch 39/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - loss: 4403.3740 - mean_absolute_error: 49.3231 - mse: 4403.3740 - val_loss: 4279.1118 - val_mean_absolute_error: 48.2414 - val_mse: 4279.1118\n",
      "Epoch 40/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 4216.7480 - mean_absolute_error: 48.2938 - mse: 4216.7480 - val_loss: 4266.6982 - val_mean_absolute_error: 48.8248 - val_mse: 4266.6982\n",
      "Epoch 41/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 4115.0894 - mean_absolute_error: 48.2051 - mse: 4115.0894 - val_loss: 4310.7529 - val_mean_absolute_error: 47.6274 - val_mse: 4310.7529\n",
      "Epoch 42/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - loss: 4057.7783 - mean_absolute_error: 46.6654 - mse: 4057.7783 - val_loss: 4303.8652 - val_mean_absolute_error: 47.3693 - val_mse: 4303.8652\n",
      "Epoch 43/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 4033.1812 - mean_absolute_error: 47.3710 - mse: 4033.1812 - val_loss: 4255.8140 - val_mean_absolute_error: 48.7943 - val_mse: 4255.8140\n",
      "Epoch 44/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - loss: 4040.6887 - mean_absolute_error: 47.6282 - mse: 4040.6887 - val_loss: 4263.7114 - val_mean_absolute_error: 48.3212 - val_mse: 4263.7114\n",
      "Epoch 45/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - loss: 3764.6921 - mean_absolute_error: 46.2072 - mse: 3764.6921 - val_loss: 4419.1914 - val_mean_absolute_error: 47.6652 - val_mse: 4419.1914\n",
      "Epoch 46/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - loss: 3785.4758 - mean_absolute_error: 47.1487 - mse: 3785.4758 - val_loss: 4241.7026 - val_mean_absolute_error: 48.0247 - val_mse: 4241.7026\n",
      "Epoch 47/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - loss: 3800.1807 - mean_absolute_error: 46.3271 - mse: 3800.1807 - val_loss: 4297.7686 - val_mean_absolute_error: 49.0609 - val_mse: 4297.7686\n",
      "Epoch 48/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - loss: 3962.9255 - mean_absolute_error: 47.3198 - mse: 3962.9255 - val_loss: 4440.4512 - val_mean_absolute_error: 50.6270 - val_mse: 4440.4512\n",
      "Epoch 49/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - loss: 3905.8604 - mean_absolute_error: 47.4463 - mse: 3905.8604 - val_loss: 4300.4136 - val_mean_absolute_error: 48.8799 - val_mse: 4300.4136\n",
      "Epoch 50/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 3737.4873 - mean_absolute_error: 46.4357 - mse: 3737.4873 - val_loss: 4485.7646 - val_mean_absolute_error: 47.7232 - val_mse: 4485.7646\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MSE Modelo 1: 5132.375957585819\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(36, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(18, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model1.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_error', 'mse'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "batch_size = 1\n",
    "epochs = 50\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred1 = model1.predict(X_test).flatten()  # Garantir compatibilidade de forma com y_test\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse1 = mean_squared_error(y_test, y_pred1)\n",
    "print(f'MSE Modelo 1: {mse1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo 2: Mês e Ano Discretizados Trigonometricamente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação trigonométrica para o mês e ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# colunas 'month' e 'year' para o tipo inteiro\n",
    "data_process['month'] = data_process['month'].astype(int)\n",
    "data_process['year'] = data_process['year'].astype(int)\n",
    "\n",
    "# Transformação trigonométrica\n",
    "data_process['month_sin'] = np.sin(2 * np.pi * data_process['month'] / 12)\n",
    "data_process['month_cos'] = np.cos(2 * np.pi * data_process['month'] / 12)\n",
    "data_process['year_sin'] = np.sin(2 * np.pi * (data_process['year'] - data_process['year'].min()) / (data_process['year'].max() - data_process['year'].min()))\n",
    "data_process['year_cos'] = np.cos(2 * np.pi * (data_process['year'] - data_process['year'].min()) / (data_process['year'].max() - data_process['year'].min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir Treino e Teste e Criar o Modelo Semelhante ao anterior do modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar variáveis dummy para 'AREA'\n",
    "data_dummies2 = pd.get_dummies(data_process, columns=['AREA'])\n",
    "\n",
    "# Dividir os dados para treino e teste\n",
    "X2 = data_dummies2[['month_sin', 'month_cos', 'year_sin', 'year_cos'] + [col for col in data_dummies2.columns if 'AREA_' in col]]\n",
    "y2 = data_dummies2['counts']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir o novo modelo neural com mesma arquitetura, Treinar, Fazer previsões e Avaliar o MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691us/step - loss: 47231.7422 - mean_absolute_error: 169.5546 - mse: 47231.7422 - val_loss: 5292.9546 - val_mean_absolute_error: 56.8901 - val_mse: 5292.9546\n",
      "Epoch 2/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - loss: 4368.1470 - mean_absolute_error: 52.7498 - mse: 4368.1470 - val_loss: 5006.3223 - val_mean_absolute_error: 53.7179 - val_mse: 5006.3223\n",
      "Epoch 3/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - loss: 4379.4258 - mean_absolute_error: 52.4623 - mse: 4379.4258 - val_loss: 4822.5713 - val_mean_absolute_error: 51.5164 - val_mse: 4822.5713\n",
      "Epoch 4/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - loss: 4192.0752 - mean_absolute_error: 49.9877 - mse: 4192.0752 - val_loss: 4629.5942 - val_mean_absolute_error: 50.2938 - val_mse: 4629.5942\n",
      "Epoch 5/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - loss: 4076.3513 - mean_absolute_error: 49.3565 - mse: 4076.3513 - val_loss: 4523.6128 - val_mean_absolute_error: 49.1358 - val_mse: 4523.6128\n",
      "Epoch 6/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - loss: 3849.7727 - mean_absolute_error: 47.6752 - mse: 3849.7727 - val_loss: 4454.7407 - val_mean_absolute_error: 48.0246 - val_mse: 4454.7407\n",
      "Epoch 7/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - loss: 4030.3076 - mean_absolute_error: 48.4467 - mse: 4030.3076 - val_loss: 4403.8521 - val_mean_absolute_error: 47.3479 - val_mse: 4403.8521\n",
      "Epoch 8/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - loss: 4060.7664 - mean_absolute_error: 48.0726 - mse: 4060.7664 - val_loss: 4473.2163 - val_mean_absolute_error: 47.6441 - val_mse: 4473.2163\n",
      "Epoch 9/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 3761.6843 - mean_absolute_error: 46.6402 - mse: 3761.6843 - val_loss: 4527.2788 - val_mean_absolute_error: 48.3862 - val_mse: 4527.2788\n",
      "Epoch 10/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - loss: 3803.6194 - mean_absolute_error: 47.6939 - mse: 3803.6194 - val_loss: 4466.4028 - val_mean_absolute_error: 48.9231 - val_mse: 4466.4028\n",
      "Epoch 11/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - loss: 3899.0127 - mean_absolute_error: 47.6982 - mse: 3899.0127 - val_loss: 4787.6313 - val_mean_absolute_error: 50.5658 - val_mse: 4787.6313\n",
      "Epoch 12/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - loss: 3830.4353 - mean_absolute_error: 47.8382 - mse: 3830.4353 - val_loss: 4499.2163 - val_mean_absolute_error: 48.9423 - val_mse: 4499.2163\n",
      "Epoch 13/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - loss: 3798.1294 - mean_absolute_error: 47.7942 - mse: 3798.1294 - val_loss: 4770.6924 - val_mean_absolute_error: 49.5125 - val_mse: 4770.6924\n",
      "Epoch 14/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 3639.0332 - mean_absolute_error: 45.9425 - mse: 3639.0332 - val_loss: 4514.7402 - val_mean_absolute_error: 48.1602 - val_mse: 4514.7402\n",
      "Epoch 15/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - loss: 3718.8804 - mean_absolute_error: 46.1387 - mse: 3718.8804 - val_loss: 4480.3813 - val_mean_absolute_error: 48.0084 - val_mse: 4480.3813\n",
      "Epoch 16/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - loss: 3559.3889 - mean_absolute_error: 45.6622 - mse: 3559.3889 - val_loss: 4567.4849 - val_mean_absolute_error: 48.5952 - val_mse: 4567.4849\n",
      "Epoch 17/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 3912.3850 - mean_absolute_error: 47.0969 - mse: 3912.3850 - val_loss: 4592.2305 - val_mean_absolute_error: 47.3798 - val_mse: 4592.2305\n",
      "Epoch 18/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - loss: 3369.8413 - mean_absolute_error: 43.9968 - mse: 3369.8413 - val_loss: 4488.2749 - val_mean_absolute_error: 48.5261 - val_mse: 4488.2749\n",
      "Epoch 19/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 3771.5085 - mean_absolute_error: 46.9777 - mse: 3771.5085 - val_loss: 4489.3135 - val_mean_absolute_error: 47.5061 - val_mse: 4489.3135\n",
      "Epoch 20/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - loss: 3778.1863 - mean_absolute_error: 47.1481 - mse: 3778.1863 - val_loss: 4560.6938 - val_mean_absolute_error: 47.8324 - val_mse: 4560.6938\n",
      "Epoch 21/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 3779.3503 - mean_absolute_error: 46.4636 - mse: 3779.3503 - val_loss: 4602.2559 - val_mean_absolute_error: 48.0345 - val_mse: 4602.2559\n",
      "Epoch 22/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - loss: 3536.9583 - mean_absolute_error: 44.6443 - mse: 3536.9583 - val_loss: 4597.5220 - val_mean_absolute_error: 48.4637 - val_mse: 4597.5220\n",
      "Epoch 23/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - loss: 3528.2290 - mean_absolute_error: 45.8523 - mse: 3528.2290 - val_loss: 4768.2202 - val_mean_absolute_error: 49.9782 - val_mse: 4768.2202\n",
      "Epoch 24/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - loss: 3796.0891 - mean_absolute_error: 46.1546 - mse: 3796.0891 - val_loss: 4573.0420 - val_mean_absolute_error: 49.2011 - val_mse: 4573.0420\n",
      "Epoch 25/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - loss: 3650.6057 - mean_absolute_error: 45.7433 - mse: 3650.6057 - val_loss: 4542.8320 - val_mean_absolute_error: 48.4424 - val_mse: 4542.8320\n",
      "Epoch 26/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 3462.6177 - mean_absolute_error: 45.2193 - mse: 3462.6177 - val_loss: 4542.8447 - val_mean_absolute_error: 47.7857 - val_mse: 4542.8447\n",
      "Epoch 27/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585us/step - loss: 3708.0125 - mean_absolute_error: 46.0814 - mse: 3708.0125 - val_loss: 4569.1631 - val_mean_absolute_error: 48.5379 - val_mse: 4569.1631\n",
      "Epoch 28/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - loss: 3587.0979 - mean_absolute_error: 45.4103 - mse: 3587.0979 - val_loss: 4685.2583 - val_mean_absolute_error: 48.6102 - val_mse: 4685.2583\n",
      "Epoch 29/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 3562.5139 - mean_absolute_error: 45.6502 - mse: 3562.5139 - val_loss: 4578.7759 - val_mean_absolute_error: 48.0746 - val_mse: 4578.7759\n",
      "Epoch 30/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - loss: 3639.1899 - mean_absolute_error: 45.4088 - mse: 3639.1899 - val_loss: 4565.7534 - val_mean_absolute_error: 48.1891 - val_mse: 4565.7534\n",
      "Epoch 31/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 3746.8633 - mean_absolute_error: 46.0050 - mse: 3746.8633 - val_loss: 4589.2295 - val_mean_absolute_error: 49.3466 - val_mse: 4589.2295\n",
      "Epoch 32/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 3697.5586 - mean_absolute_error: 45.9351 - mse: 3697.5586 - val_loss: 4678.3486 - val_mean_absolute_error: 49.0164 - val_mse: 4678.3486\n",
      "Epoch 33/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - loss: 3502.1484 - mean_absolute_error: 44.3659 - mse: 3502.1484 - val_loss: 4627.5933 - val_mean_absolute_error: 49.2836 - val_mse: 4627.5933\n",
      "Epoch 34/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 3784.2854 - mean_absolute_error: 46.8898 - mse: 3784.2854 - val_loss: 4925.2900 - val_mean_absolute_error: 51.1282 - val_mse: 4925.2900\n",
      "Epoch 35/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 3543.5852 - mean_absolute_error: 45.3946 - mse: 3543.5852 - val_loss: 4623.9277 - val_mean_absolute_error: 48.3284 - val_mse: 4623.9277\n",
      "Epoch 36/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 3466.6946 - mean_absolute_error: 45.1720 - mse: 3466.6946 - val_loss: 4691.2686 - val_mean_absolute_error: 48.5986 - val_mse: 4691.2686\n",
      "Epoch 37/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - loss: 3433.6853 - mean_absolute_error: 43.8618 - mse: 3433.6853 - val_loss: 4763.0767 - val_mean_absolute_error: 50.2649 - val_mse: 4763.0767\n",
      "Epoch 38/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - loss: 3336.0515 - mean_absolute_error: 44.6685 - mse: 3336.0515 - val_loss: 4576.5874 - val_mean_absolute_error: 49.5151 - val_mse: 4576.5874\n",
      "Epoch 39/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - loss: 3557.4590 - mean_absolute_error: 45.1395 - mse: 3557.4590 - val_loss: 4639.4512 - val_mean_absolute_error: 47.9432 - val_mse: 4639.4512\n",
      "Epoch 40/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 3250.9551 - mean_absolute_error: 43.1208 - mse: 3250.9551 - val_loss: 4564.3989 - val_mean_absolute_error: 48.3354 - val_mse: 4564.3989\n",
      "Epoch 41/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 3381.0205 - mean_absolute_error: 44.5514 - mse: 3381.0205 - val_loss: 4581.8667 - val_mean_absolute_error: 48.6950 - val_mse: 4581.8667\n",
      "Epoch 42/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - loss: 3952.6760 - mean_absolute_error: 46.3747 - mse: 3952.6760 - val_loss: 4655.8892 - val_mean_absolute_error: 49.4167 - val_mse: 4655.8892\n",
      "Epoch 43/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 3256.2500 - mean_absolute_error: 43.5901 - mse: 3256.2500 - val_loss: 4599.3823 - val_mean_absolute_error: 48.3098 - val_mse: 4599.3823\n",
      "Epoch 44/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 3627.7056 - mean_absolute_error: 45.8967 - mse: 3627.7056 - val_loss: 4656.2173 - val_mean_absolute_error: 48.1402 - val_mse: 4656.2173\n",
      "Epoch 45/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 3370.9570 - mean_absolute_error: 43.4733 - mse: 3370.9570 - val_loss: 4572.4995 - val_mean_absolute_error: 48.4177 - val_mse: 4572.4995\n",
      "Epoch 46/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 3640.8052 - mean_absolute_error: 45.6654 - mse: 3640.8052 - val_loss: 4570.3496 - val_mean_absolute_error: 48.4111 - val_mse: 4570.3496\n",
      "Epoch 47/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 3452.8804 - mean_absolute_error: 44.7258 - mse: 3452.8804 - val_loss: 4853.2773 - val_mean_absolute_error: 50.3449 - val_mse: 4853.2773\n",
      "Epoch 48/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 3348.0645 - mean_absolute_error: 44.0151 - mse: 3348.0645 - val_loss: 4799.4766 - val_mean_absolute_error: 48.8325 - val_mse: 4799.4766\n",
      "Epoch 49/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 3459.8403 - mean_absolute_error: 44.1588 - mse: 3459.8403 - val_loss: 4756.7656 - val_mean_absolute_error: 48.5225 - val_mse: 4756.7656\n",
      "Epoch 50/50\n",
      "\u001b[1m2083/2083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 3245.9475 - mean_absolute_error: 43.0186 - mse: 3245.9475 - val_loss: 4569.6655 - val_mean_absolute_error: 49.4570 - val_mse: 4569.6655\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MSE Modelo 2: 5435.270547373243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = X_train2.shape[1]\n",
    "model2 = Sequential([\n",
    "    Dense(36, input_shape=(input_shape,), activation='relu'),\n",
    "    Dense(18, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model2.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_error', 'mse'])\n",
    "\n",
    "history2 = model2.fit(X_train2, y_train2, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "mse2 = mean_squared_error(y_test2, y_pred2)\n",
    "print(f'MSE Modelo 2: {mse2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janelamento para 3 Meses: criar um dataframe para cada área e considerar apenas as contagens dos 3 meses anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do Janelamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df):\n",
    "    for i in range(1, 4):\n",
    "        df[f'counts_lag_{i}'] = df['counts'].shift(i)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando janelamento em cada área\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101821/1779380499.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_lagged = data_process.groupby('AREA').apply(create_lagged_features).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data_lagged = data_process.groupby('AREA').apply(create_lagged_features).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remover valores nulos provenientes do janelamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lagged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir o Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = data_lagged[[f'counts_lag_{i}' for i in range(1, 4)] + ['month', 'year']]\n",
    "y3 = data_lagged['counts']\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o modelo analogo aos anteriores, Treinar e avaliar o MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - loss: 7946.8369 - mean_absolute_error: 57.0944 - mse: 7946.8369 - val_loss: 3126.3733 - val_mean_absolute_error: 33.5303 - val_mse: 3126.3733\n",
      "Epoch 2/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 3827.1392 - mean_absolute_error: 38.3482 - mse: 3827.1392 - val_loss: 2782.3708 - val_mean_absolute_error: 31.2633 - val_mse: 2782.3708\n",
      "Epoch 3/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 3155.8462 - mean_absolute_error: 35.8267 - mse: 3155.8462 - val_loss: 2878.7556 - val_mean_absolute_error: 34.7598 - val_mse: 2878.7556\n",
      "Epoch 4/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - loss: 2760.0452 - mean_absolute_error: 34.0678 - mse: 2760.0452 - val_loss: 2851.4053 - val_mean_absolute_error: 33.7734 - val_mse: 2851.4053\n",
      "Epoch 5/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - loss: 3239.8376 - mean_absolute_error: 35.3196 - mse: 3239.8376 - val_loss: 3081.5098 - val_mean_absolute_error: 35.2604 - val_mse: 3081.5098\n",
      "Epoch 6/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - loss: 3697.3953 - mean_absolute_error: 36.2554 - mse: 3697.3953 - val_loss: 2788.2659 - val_mean_absolute_error: 33.0992 - val_mse: 2788.2659\n",
      "Epoch 7/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - loss: 2871.9475 - mean_absolute_error: 35.0094 - mse: 2871.9475 - val_loss: 2671.2544 - val_mean_absolute_error: 32.8768 - val_mse: 2671.2544\n",
      "Epoch 8/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - loss: 3160.9788 - mean_absolute_error: 33.9243 - mse: 3160.9788 - val_loss: 2580.7581 - val_mean_absolute_error: 31.6903 - val_mse: 2580.7581\n",
      "Epoch 9/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - loss: 2847.0056 - mean_absolute_error: 32.7599 - mse: 2847.0056 - val_loss: 2919.2188 - val_mean_absolute_error: 34.6151 - val_mse: 2919.2188\n",
      "Epoch 10/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - loss: 3151.9639 - mean_absolute_error: 34.0380 - mse: 3151.9639 - val_loss: 2579.7102 - val_mean_absolute_error: 32.2969 - val_mse: 2579.7102\n",
      "Epoch 11/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 2738.6812 - mean_absolute_error: 32.6932 - mse: 2738.6812 - val_loss: 2903.3184 - val_mean_absolute_error: 34.7550 - val_mse: 2903.3184\n",
      "Epoch 12/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 3220.7161 - mean_absolute_error: 34.0980 - mse: 3220.7161 - val_loss: 2786.5205 - val_mean_absolute_error: 34.6727 - val_mse: 2786.5205\n",
      "Epoch 13/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 2692.2002 - mean_absolute_error: 33.2004 - mse: 2692.2002 - val_loss: 3449.2529 - val_mean_absolute_error: 40.8808 - val_mse: 3449.2529\n",
      "Epoch 14/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 3321.8962 - mean_absolute_error: 36.3074 - mse: 3321.8962 - val_loss: 2646.6189 - val_mean_absolute_error: 34.5534 - val_mse: 2646.6189\n",
      "Epoch 15/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 2784.3674 - mean_absolute_error: 32.5214 - mse: 2784.3674 - val_loss: 2544.2822 - val_mean_absolute_error: 32.2937 - val_mse: 2544.2822\n",
      "Epoch 16/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - loss: 2837.4714 - mean_absolute_error: 34.7594 - mse: 2837.4714 - val_loss: 2476.5737 - val_mean_absolute_error: 32.4306 - val_mse: 2476.5737\n",
      "Epoch 17/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 2683.3318 - mean_absolute_error: 31.1839 - mse: 2683.3318 - val_loss: 2441.4038 - val_mean_absolute_error: 31.6990 - val_mse: 2441.4038\n",
      "Epoch 18/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - loss: 3217.9978 - mean_absolute_error: 33.4600 - mse: 3217.9978 - val_loss: 2493.5115 - val_mean_absolute_error: 32.9867 - val_mse: 2493.5115\n",
      "Epoch 19/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 2241.1892 - mean_absolute_error: 31.4950 - mse: 2241.1892 - val_loss: 2767.2913 - val_mean_absolute_error: 34.9483 - val_mse: 2767.2913\n",
      "Epoch 20/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 2551.7231 - mean_absolute_error: 32.4447 - mse: 2551.7231 - val_loss: 2342.8213 - val_mean_absolute_error: 31.4850 - val_mse: 2342.8213\n",
      "Epoch 21/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 2744.4255 - mean_absolute_error: 33.2185 - mse: 2744.4255 - val_loss: 2571.6599 - val_mean_absolute_error: 33.3931 - val_mse: 2571.6599\n",
      "Epoch 22/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 2390.7896 - mean_absolute_error: 31.0850 - mse: 2390.7896 - val_loss: 2425.5398 - val_mean_absolute_error: 32.1141 - val_mse: 2425.5398\n",
      "Epoch 23/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - loss: 2685.0139 - mean_absolute_error: 32.9354 - mse: 2685.0139 - val_loss: 2333.0376 - val_mean_absolute_error: 31.6698 - val_mse: 2333.0376\n",
      "Epoch 24/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - loss: 2516.8145 - mean_absolute_error: 32.7626 - mse: 2516.8145 - val_loss: 2358.8982 - val_mean_absolute_error: 32.8030 - val_mse: 2358.8982\n",
      "Epoch 25/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - loss: 2772.7361 - mean_absolute_error: 34.4161 - mse: 2772.7361 - val_loss: 2314.5071 - val_mean_absolute_error: 32.2613 - val_mse: 2314.5071\n",
      "Epoch 26/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 2499.0654 - mean_absolute_error: 32.3542 - mse: 2499.0654 - val_loss: 2580.3735 - val_mean_absolute_error: 35.1490 - val_mse: 2580.3735\n",
      "Epoch 27/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 2802.5452 - mean_absolute_error: 33.4962 - mse: 2802.5452 - val_loss: 2463.0061 - val_mean_absolute_error: 32.6533 - val_mse: 2463.0061\n",
      "Epoch 28/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - loss: 2746.1978 - mean_absolute_error: 33.3845 - mse: 2746.1978 - val_loss: 2147.1663 - val_mean_absolute_error: 30.6791 - val_mse: 2147.1663\n",
      "Epoch 29/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 2437.1865 - mean_absolute_error: 32.8259 - mse: 2437.1865 - val_loss: 2108.4163 - val_mean_absolute_error: 29.9566 - val_mse: 2108.4163\n",
      "Epoch 30/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - loss: 2412.7205 - mean_absolute_error: 31.3210 - mse: 2412.7205 - val_loss: 2421.0295 - val_mean_absolute_error: 33.7019 - val_mse: 2421.0295\n",
      "Epoch 31/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 2291.3892 - mean_absolute_error: 30.8007 - mse: 2291.3892 - val_loss: 2169.2205 - val_mean_absolute_error: 32.5877 - val_mse: 2169.2205\n",
      "Epoch 32/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 2431.3210 - mean_absolute_error: 32.4404 - mse: 2431.3210 - val_loss: 2183.6113 - val_mean_absolute_error: 30.0106 - val_mse: 2183.6113\n",
      "Epoch 33/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 2276.0603 - mean_absolute_error: 30.2482 - mse: 2276.0603 - val_loss: 2047.5432 - val_mean_absolute_error: 31.6567 - val_mse: 2047.5432\n",
      "Epoch 34/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 2538.4431 - mean_absolute_error: 31.5162 - mse: 2538.4431 - val_loss: 1949.8478 - val_mean_absolute_error: 29.1651 - val_mse: 1949.8478\n",
      "Epoch 35/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 2190.9292 - mean_absolute_error: 31.2376 - mse: 2190.9292 - val_loss: 2023.3125 - val_mean_absolute_error: 32.2156 - val_mse: 2023.3125\n",
      "Epoch 36/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - loss: 2686.4792 - mean_absolute_error: 31.7595 - mse: 2686.4792 - val_loss: 2277.2156 - val_mean_absolute_error: 32.9788 - val_mse: 2277.2156\n",
      "Epoch 37/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - loss: 2085.0222 - mean_absolute_error: 29.9603 - mse: 2085.0222 - val_loss: 2289.6333 - val_mean_absolute_error: 32.7425 - val_mse: 2289.6333\n",
      "Epoch 38/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 2497.8362 - mean_absolute_error: 32.7292 - mse: 2497.8362 - val_loss: 2119.7302 - val_mean_absolute_error: 32.1274 - val_mse: 2119.7302\n",
      "Epoch 39/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - loss: 2292.7275 - mean_absolute_error: 32.1732 - mse: 2292.7275 - val_loss: 1834.7837 - val_mean_absolute_error: 29.3107 - val_mse: 1834.7837\n",
      "Epoch 40/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - loss: 2312.2917 - mean_absolute_error: 30.4016 - mse: 2312.2917 - val_loss: 1979.3103 - val_mean_absolute_error: 31.1600 - val_mse: 1979.3103\n",
      "Epoch 41/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 2329.9385 - mean_absolute_error: 30.9684 - mse: 2329.9385 - val_loss: 1873.3893 - val_mean_absolute_error: 30.5579 - val_mse: 1873.3893\n",
      "Epoch 42/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - loss: 2139.2646 - mean_absolute_error: 30.7125 - mse: 2139.2646 - val_loss: 1758.1034 - val_mean_absolute_error: 28.9756 - val_mse: 1758.1034\n",
      "Epoch 43/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 2288.7109 - mean_absolute_error: 30.6920 - mse: 2288.7109 - val_loss: 1623.6271 - val_mean_absolute_error: 27.7421 - val_mse: 1623.6271\n",
      "Epoch 44/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - loss: 2044.8750 - mean_absolute_error: 29.5202 - mse: 2044.8750 - val_loss: 1731.1738 - val_mean_absolute_error: 28.5989 - val_mse: 1731.1738\n",
      "Epoch 45/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - loss: 2537.4617 - mean_absolute_error: 31.0163 - mse: 2537.4617 - val_loss: 2041.3199 - val_mean_absolute_error: 29.5020 - val_mse: 2041.3199\n",
      "Epoch 46/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 2065.7778 - mean_absolute_error: 30.0983 - mse: 2065.7778 - val_loss: 2366.8728 - val_mean_absolute_error: 30.7665 - val_mse: 2366.8728\n",
      "Epoch 47/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - loss: 2430.8816 - mean_absolute_error: 31.7826 - mse: 2430.8816 - val_loss: 1694.6483 - val_mean_absolute_error: 29.6727 - val_mse: 1694.6483\n",
      "Epoch 48/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - loss: 2294.9299 - mean_absolute_error: 30.3982 - mse: 2294.9299 - val_loss: 1820.1124 - val_mean_absolute_error: 29.8882 - val_mse: 1820.1124\n",
      "Epoch 49/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 2137.4905 - mean_absolute_error: 29.0350 - mse: 2137.4905 - val_loss: 1825.7683 - val_mean_absolute_error: 29.7806 - val_mse: 1825.7683\n",
      "Epoch 50/50\n",
      "\u001b[1m2042/2042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - loss: 2098.8799 - mean_absolute_error: 29.9413 - mse: 2098.8799 - val_loss: 1569.8177 - val_mean_absolute_error: 28.5951 - val_mse: 1569.8177\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MSE Modelo 3: 1549.860346021481\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train3.shape[1]\n",
    "model3 = Sequential([\n",
    "    Dense(36, input_shape=(input_shape,), activation='relu'),\n",
    "    Dense(18, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model3.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_error', 'mse'])\n",
    "\n",
    "history3 = model3.fit(X_train3, y_train3, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "\n",
    "# previsão e avalição do modelo\n",
    "y_pred3 = model3.predict(X_test3)\n",
    "mse3 = mean_squared_error(y_test3, y_pred3)\n",
    "print(f'MSE Modelo 3: {mse3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando o MSE dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Modelo 1: Mês e Ano Discretizados, como variáveis de entrada: 5132.375957585819\n",
      "MSE Modelo 2: Janelamento para 3 Meses: 5435.270547373243\n",
      "MSE Modelo 3: Mês e Ano Discretizados Trigonometricamente: 1549.860346021481\n",
      "Modelo 3 teve o melhor desempenho.\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE Modelo 1: Mês e Ano Discretizados, como variáveis de entrada: {mse1}')\n",
    "print(f'MSE Modelo 2: Janelamento para 3 Meses: {mse2}')\n",
    "print(f'MSE Modelo 3: Mês e Ano Discretizados Trigonometricamente: {mse3}')\n",
    "\n",
    "# Avaliação final\n",
    "if mse1 < mse2 and mse1 < mse3:\n",
    "    print(\"Modelo 1 teve o melhor desempenho.\")\n",
    "elif mse2 < mse1 and mse2 < mse3:\n",
    "    print(\"Modelo 2 teve o melhor desempenho.\")\n",
    "else:\n",
    "    print(\"Modelo 3 teve o melhor desempenho.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supondo que já calculamos os valores de MSE para cada modelo\n",
    "mse_values = [mse1, mse2, mse3]\n",
    "model_names = ['Modelo 1', 'Modelo 2', 'Modelo 3']\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(model_names, mse_values, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Comparação do MSE entre os Modelos')\n",
    "plt.ylim(0, max(mse_values) * 1.1)  # Ajusta o limite do eixo y para dar um espaço extra\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManchineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
