{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação de dependecências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:05:24.963596Z",
     "start_time": "2024-12-03T18:05:20.114785Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install opencv-python\n",
    "%pip install -U torch torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install transformers python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas e configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:05:29.771944Z",
     "start_time": "2024-12-03T18:05:24.980469Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-04 19:38:03.277623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-04 19:38:03.290755: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-04 19:38:03.295650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-04 19:38:03.359482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Treinamento do modelo OCR\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Configurar o caminho do dataset\n",
    "DATASET_PATH = \"/home/guilherme/Documentos/Dataset's/WaterMeters\"\n",
    "CSV_FILE = os.path.join(DATASET_PATH, \"data.csv\")\n",
    "IMAGES_FOLDER = os.path.join(DATASET_PATH, \"images\")\n",
    "MASKS_FOLDER = os.path.join(DATASET_PATH, \"masks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carregar o arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:05:29.860064Z",
     "start_time": "2024-12-03T18:05:29.845183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 photo_name    value  \\\n",
      "0   id_53_value_595_825.jpg  595.825   \n",
      "1   id_553_value_65_475.jpg   65.475   \n",
      "2    id_407_value_21_86.jpg   21.860   \n",
      "3  id_252_value_313_322.jpg  313.322   \n",
      "4  id_851_value_305_162.jpg  305.162   \n",
      "\n",
      "                                            location  \n",
      "0  {'type': 'polygon', 'data': [{'x': 0.30788, 'y...  \n",
      "1  {'type': 'polygon', 'data': [{'x': 0.26133, 'y...  \n",
      "2  {'type': 'polygon', 'data': [{'x': 0.27545, 'y...  \n",
      "3  {'type': 'polygon', 'data': [{'x': 0.21967, 'y...  \n",
      "4  {'type': 'polygon', 'data': [{'x': 0.06983, 'y...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244 entries, 0 to 1243\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   photo_name  1244 non-null   object \n",
      " 1   value       1244 non-null   float64\n",
      " 2   location    1244 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 29.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Carregar o arquivo CSV com informações das imagens\n",
    "data = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(data.head())\n",
    "\n",
    "# Verificar estatísticas do dataset\n",
    "print(data.info())\n",
    "\n",
    "# Divisão em treino e teste (80% treino, 20% teste)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar uma ROI com base na máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:05:29.895191Z",
     "start_time": "2024-12-03T18:05:29.891912Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_roi(imagem, maskara):\n",
    "    image = cv2.imread(imagem)\n",
    "    mask = cv2.imread(maskara, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Aplicar máscara para obter a ROI\n",
    "    roi = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar modelo OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:05:50.441785Z",
     "start_time": "2024-12-03T18:05:29.947423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 995/995 [00:11<00:00, 89.43it/s]\n",
      "100%|██████████| 249/249 [00:06<00:00, 41.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Configuração do modelo\n",
    "processor = DonutProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# Função para preparar os dados para o modelo\n",
    "def prepare_data(data, images_path, masks_path):\n",
    "    ocr_inputs = []\n",
    "    ocr_labels = []\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        image_file = os.path.join(images_path, row['photo_name'])\n",
    "        mask_file = os.path.join(masks_path, row['photo_name'])\n",
    "        true_value = row['value']\n",
    "\n",
    "        if os.path.exists(image_file) and os.path.exists(mask_file):\n",
    "            roi = load_roi(image_file, mask_file)\n",
    "            ocr_inputs.append(roi)\n",
    "            ocr_labels.append(true_value)\n",
    "    return ocr_inputs, ocr_labels\n",
    "\n",
    "# Preparar dados de treino\n",
    "train_images, train_labels = prepare_data(train_data, IMAGES_FOLDER, MASKS_FOLDER)\n",
    "\n",
    "# Preparar dados de teste\n",
    "test_images, test_labels = prepare_data(test_data, IMAGES_FOLDER, MASKS_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando treinamendo do modelo OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-03T18:05:50.546877Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/ManchineLearning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-04 19:52:14.177201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-04 19:52:14.190118: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-04 19:52:14.193530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-04 19:52:14.201976: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Configuração do treinamento\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./ocr_model\",\n",
    "    eval_strategy=\"steps\",\n",
    "    num_train_epochs=5.0,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Conversão dos dados para o formato necessário\n",
    "train_encodings = processor(train_images, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "train_labels_enc = processor.tokenizer(train_labels, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "\n",
    "test_encodings = processor(test_images, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "test_labels_enc = processor.tokenizer(test_labels, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Configurar o Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset={\"input_ids\": train_encodings.input_ids, \"labels\": train_labels_enc.input_ids},\n",
    "    eval_dataset={\"input_ids\": test_encodings.input_ids, \"labels\": test_labels_enc.input_ids},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando se o modelo esta prevendo corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato dos dados de treino: (796, 1333, 1000, 3), (796,)\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "def predict_and_evaluate(images, true_labels):\n",
    "    predictions = []\n",
    "    for image, true_label in tqdm(zip(images, true_labels), total=len(images)):\n",
    "        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        predictions.append(predicted_text)\n",
    "        print(f\"Verdadeiro: {true_label} | Previsto: {predicted_text}\")\n",
    "    return predictions\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "predicted_labels = predict_and_evaluate(test_images, test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManchineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
